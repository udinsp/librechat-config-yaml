version: 1.2.1

cache: true

# interface:
#   privacyPolicy:
#     externalUrl: 'https://librechat.ai/privacy-policy'
#     openNewTab: true
#   termsOfService:
#     externalUrl: 'https://librechat.ai/tos'
#     openNewTab: true

registration:
  socialLogins:
    - "discord"
    - "facebook"
    - "github"
    - "google"
    - "openid"

endpoints:
  custom:

    # cohere
    # Model list: https://dashboard.cohere.com/playground/chat
    - name: "Cohere"
      apiKey: "${COHERE_API_KEY}"
      baseURL: "https://api.cohere.ai/v1"
      models:
        default:
          - c4ai-aya-expanse-32b
          - command
          - command-light-nightly
          - command-r
          - command-r-08-2024
          - command-r-plus
          - command-r-plus-08-2024
          - command-r7b-12-2024
        fetch: false
      modelDisplayLabel: "Cohere"
      titleConvo: true
      titleModel: "command"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"
        - "temperature"
        - "top_p"

    # Exa
    - name: "Exa"
      apiKey: "${EXA_API_KEY}"
      baseURL: "https://api.exa.ai"
      iconURL: "https://media.theresanaiforthat.com/icons/exa.svg"
      models:
        default:
          - exa
          - exa-pro
        fetch: false
      modelDisplayLabel: "Exa"
      titleConvo: true
      titleModel: "exa"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"

    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "Groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default:
          - deepseek-r1-distill-llama-70b
          - deepseek-r1-distill-qwen-32b
          - gemma2-9b-it
          - llama-3.1-8b-instant
          - llama-3.2-11b-vision-preview
          - llama-3.2-1b-preview
          - llama-3.2-3b-preview
          - llama-3.2-90b-vision-preview
          - llama-3.3-70b-specdec
          - llama-3.3-70b-versatile
          - llama-guard-3-8b
          - llama3-70b-8192
          - llama3-8b-8192
          - mixtral-8x7b-32768
          - qwen-2.5-32b
          - qwen-2.5-coder-32b
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "Groq"

    # Mistral AI API
    # Model list: https://docs.mistral.ai/getting-started/models/
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default:
          - codestral-2405
          - codestral-2411-rc5
          - codestral-2412
          - codestral-2501
          - codestral-latest
          - codestral-mamba-2407
          - codestral-mamba-latest
          - ministral-3b-2410
          - ministral-3b-latest
          - ministral-8b-2410
          - ministral-8b-latest
          - mistral-embed
          - mistral-large-2402
          - mistral-large-2407
          - mistral-large-2411
          - mistral-large-latest
          - mistral-large-pixtral-2411
          - mistral-medium
          - mistral-medium-2312
          - mistral-medium-latest
          - mistral-moderation-2411
          - mistral-moderation-latest
          - mistral-saba-2502
          - mistral-saba-latest
          - mistral-small
          - mistral-small-2312
          - mistral-small-2402
          - mistral-small-2409
          - mistral-small-2501
          - mistral-small-latest
          - mistral-tiny
          - mistral-tiny-2312
          - mistral-tiny-2407
          - mistral-tiny-latest
          - open-codestral-mamba
          - open-mistral-7b
          - open-mistral-nemo
          - open-mistral-nemo-2407
          - open-mixtral-8x22b
          - open-mixtral-8x22b-2404
          - open-mixtral-8x7b
          - pixtral-12b
          - pixtral-12b-2409
          - pixtral-12b-latest
          - pixtral-large-2411
          - pixtral-large-latest
        fetch: false
      titleConvo: true
      titleModel: "mistral-tiny"
      modelDisplayLabel: "Mistral"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"

    # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default:
          - cognitivecomputations/dolphin3.0-mistral-24b:free
          - cognitivecomputations/dolphin3.0-r1-mistral-24b:free
          - deepseek/deepseek-chat:free
          - deepseek/deepseek-r1-distill-llama-70b:free
          - deepseek/deepseek-r1:free
          - google/gemini-2.0-flash-exp:free
          - google/gemini-2.0-flash-lite-preview-02-05:free
          - google/gemini-2.0-flash-thinking-exp-1219:free
          - google/gemini-2.0-flash-thinking-exp:free
          - google/gemini-2.0-pro-exp-02-05:free
          - google/gemini-exp-1206:free
          - google/gemma-2-9b-it:free
          - google/learnlm-1.5-pro-experimental:free
          - gryphe/mythomax-l2-13b:free
          - huggingfaceh4/zephyr-7b-beta:free
          - meta-llama/llama-3-8b-instruct:free
          - meta-llama/llama-3.1-8b-instruct:free
          - meta-llama/llama-3.2-11b-vision-instruct:free
          - meta-llama/llama-3.2-1b-instruct:free
          - meta-llama/llama-3.3-70b-instruct:free
          - microsoft/phi-3-medium-128k-instruct:free
          - microsoft/phi-3-mini-128k-instruct:free
          - mistralai/mistral-7b-instruct:free
          - mistralai/mistral-nemo:free
          - mistralai/mistral-small-24b-instruct-2501:free
          - nvidia/llama-3.1-nemotron-70b-instruct:free
          - openchat/openchat-7b:free
          - qwen/qwen-vl-plus:free
          - qwen/qwen2.5-vl-72b-instruct:free
          - sophosympatheia/rogue-rose-103b-v0.2:free
          - undi95/toppy-m-7b:free
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # together.ai
    # https://api.together.ai/settings/api-keys
    # Model list: https://docs.together.ai/docs/inference-models
    - name: "Together"
      apiKey: "${TOGETHERAI_API_KEY}"
      baseURL: "https://api.together.xyz"
      iconURL: "https://registry.npmmirror.com/@lobehub/icons-static-png/1.24.0/files/dark/together-color.png"
      models:
        default:
          - deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free
          - meta-llama/Llama-3.3-70B-Instruct-Turbo-Free
          - meta-llama/Llama-Vision-Free
        fetch: false
      titleConvo: true
      titleModel: "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
      summarize: false
      summaryModel: "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
      forcePrompt: false
      modelDisplayLabel: "Together AI"

    # Unify
    # Model list: https://unify.ai/chat
    - name: "Unify"
      apiKey: "${UNIFY_API_KEY}"
      baseURL: "https://api.unify.ai/v0/"
      models:
        default:
          - chatgpt-4o-latest@openai
          - claude-3-haiku@anthropic
          - claude-3-haiku@aws-bedrock
          - claude-3-haiku@vertex-ai
          - claude-3-opus@anthropic
          - claude-3-opus@aws-bedrock
          - claude-3-opus@vertex-ai
          - claude-3-sonnet@anthropic
          - claude-3-sonnet@aws-bedrock
          - claude-3-sonnet@vertex-ai
          - claude-3.5-haiku@anthropic
          - claude-3.5-haiku@aws-bedrock
          - claude-3.5-haiku@replicate
          - claude-3.5-haiku@vertex-ai
          - claude-3.5-sonnet-20240620@anthropic
          - claude-3.5-sonnet-20240620@aws-bedrock
          - claude-3.5-sonnet-20240620@vertex-ai
          - claude-3.5-sonnet@anthropic
          - claude-3.5-sonnet@aws-bedrock
          - claude-3.5-sonnet@replicate
          - claude-3.5-sonnet@vertex-ai
          - command-r-plus@aws-bedrock
          - deepseek-r1@deepinfra
          - deepseek-r1@deepseek
          - deepseek-r1@fireworks-ai
          - deepseek-r1@replicate
          - deepseek-r1@together-ai
          - deepseek-v3@deepinfra
          - deepseek-v3@deepseek
          - deepseek-v3@fireworks-ai
          - deepseek-v3@together-ai
          - gemini-1.0-pro-001@vertex-ai
          - gemini-1.0-pro-002@vertex-ai
          - gemini-1.0-pro@vertex-ai
          - gemini-1.5-flash-001@vertex-ai
          - gemini-1.5-flash-002@vertex-ai
          - gemini-1.5-flash@vertex-ai
          - gemini-1.5-pro-001@vertex-ai
          - gemini-1.5-pro-002@vertex-ai
          - gemini-1.5-pro@vertex-ai
          - gemini-2.0-flash-lite@vertex-ai
          - gemini-2.0-flash@vertex-ai
          - gemma-2-27b-it@deepinfra
          - gemma-2-27b-it@together-ai
          - gemma-2-9b-it@deepinfra
          - gemma-2-9b-it@groq
          - gemma-2-9b-it@lepton-ai
          - gemma-2-9b-it@together-ai
          - gpt-3.5-turbo@openai
          - gpt-4-turbo@openai
          - gpt-4@openai
          - gpt-4o-2024-05-13@openai
          - gpt-4o-2024-08-06@openai
          - gpt-4o-2024-11-20@openai
          - gpt-4o-mini@openai
          - gpt-4o@openai
          - grok-2-vision@xai
          - grok-2@xai
          - llama-3-70b-chat@aws-bedrock
          - llama-3-70b-chat@deepinfra
          - llama-3-70b-chat@fireworks-ai
          - llama-3-70b-chat@groq
          - llama-3-70b-chat@lepton-ai
          - llama-3-70b-chat@replicate
          - llama-3-70b-chat@together-ai
          - llama-3-8b-chat@aws-bedrock
          - llama-3-8b-chat@deepinfra
          - llama-3-8b-chat@fireworks-ai
          - llama-3-8b-chat@groq
          - llama-3-8b-chat@lepton-ai
          - llama-3-8b-chat@replicate
          - llama-3-8b-chat@together-ai
          - llama-3.1-405b-chat@aws-bedrock
          - llama-3.1-405b-chat@deepinfra
          - llama-3.1-405b-chat@fireworks-ai
          - llama-3.1-405b-chat@replicate
          - llama-3.1-405b-chat@together-ai
          - llama-3.1-405b-chat@vertex-ai
          - llama-3.1-70b-chat@aws-bedrock
          - llama-3.1-70b-chat@deepinfra
          - llama-3.1-70b-chat@fireworks-ai
          - llama-3.1-70b-chat@lepton-ai
          - llama-3.1-70b-chat@together-ai
          - llama-3.1-70b-chat@vertex-ai
          - llama-3.1-8b-chat@aws-bedrock
          - llama-3.1-8b-chat@deepinfra
          - llama-3.1-8b-chat@fireworks-ai
          - llama-3.1-8b-chat@groq
          - llama-3.1-8b-chat@lepton-ai
          - llama-3.1-8b-chat@together-ai
          - llama-3.1-8b-chat@vertex-ai
          - llama-3.1-nemotron-70b-chat@deepinfra
          - llama-3.2-11b-chat@deepinfra
          - llama-3.2-11b-chat@fireworks-ai
          - llama-3.2-11b-chat@groq
          - llama-3.2-11b-chat@together-ai
          - llama-3.2-11b-chat@vertex-ai
          - llama-3.2-1b-chat@aws-bedrock
          - llama-3.2-1b-chat@deepinfra
          - llama-3.2-1b-chat@groq
          - llama-3.2-1b-chat@lepton-ai
          - llama-3.2-3b-chat@aws-bedrock
          - llama-3.2-3b-chat@deepinfra
          - llama-3.2-3b-chat@fireworks-ai
          - llama-3.2-3b-chat@groq
          - llama-3.2-3b-chat@lepton-ai
          - llama-3.2-3b-chat@together-ai
          - llama-3.2-90b-chat@deepinfra
          - llama-3.2-90b-chat@fireworks-ai
          - llama-3.2-90b-chat@groq
          - llama-3.2-90b-chat@together-ai
          - llama-3.2-90b-chat@vertex-ai
          - llama-3.3-70b-chat@aws-bedrock
          - llama-3.3-70b-chat@deepinfra
          - llama-3.3-70b-chat@fireworks-ai
          - llama-3.3-70b-chat@groq
          - llama-3.3-70b-chat@lepton-ai
          - llama-3.3-70b-chat@together-ai
          - ministral-3b@mistral-ai
          - ministral-8b@mistral-ai
          - mistral-7b-instruct-v0.2@aws-bedrock
          - mistral-7b-instruct-v0.3@deepinfra
          - mistral-7b-instruct-v0.3@lepton-ai
          - mistral-7b-instruct-v0.3@mistral-ai
          - mistral-7b-instruct-v0.3@together-ai
          - mistral-large@aws-bedrock
          - mistral-large@mistral-ai
          - mistral-large@vertex-ai
          - mistral-nemo@deepinfra
          - mistral-nemo@lepton-ai
          - mistral-nemo@mistral-ai
          - mistral-nemo@vertex-ai
          - mistral-small@deepinfra
          - mistral-small@fireworks-ai
          - mistral-small@mistral-ai
          - mistral-small@together-ai
          - mixtral-8x22b-instruct-v0.1@fireworks-ai
          - mixtral-8x22b-instruct-v0.1@mistral-ai
          - mixtral-8x22b-instruct-v0.1@together-ai
          - mixtral-8x7b-instruct-v0.1@aws-bedrock
          - mixtral-8x7b-instruct-v0.1@deepinfra
          - mixtral-8x7b-instruct-v0.1@fireworks-ai
          - mixtral-8x7b-instruct-v0.1@groq
          - mixtral-8x7b-instruct-v0.1@lepton-ai
          - mixtral-8x7b-instruct-v0.1@mistral-ai
          - mixtral-8x7b-instruct-v0.1@replicate
          - mixtral-8x7b-instruct-v0.1@together-ai
          - o1-mini@openai
          - o1@openai
          - o3-mini@openai
          - qwen-2-72b-instruct@together-ai
          - qwen-2.5-72b-instruct@deepinfra
          - qwen-2.5-72b-instruct@fireworks-ai
          - qwen-2.5-72b-instruct@together-ai
          - qwen-2.5-7b-instruct@deepinfra
          - qwen-2.5-7b-instruct@together-ai
          - qwen-2.5-coder-32b-instruct@deepinfra
          - qwen-2.5-coder-32b-instruct@fireworks-ai
          - qwen-2.5-coder-32b-instruct@groq
          - qwen-2.5-coder-32b-instruct@together-ai
          - qwen-qwq-32b-preview@fireworks-ai
          - qwen-qwq-32b-preview@together-ai
        fetch: false
      titleModel: "gpt-4o-mini@openai"
      dropParams:
        - "stop"
        - "user"
        - "frequency_penalty"
        - "presence_penalty"

